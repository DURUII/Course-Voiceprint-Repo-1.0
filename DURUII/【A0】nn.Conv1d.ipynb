{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DURUII/HIMIA-course/blob/main/DURUII/%E3%80%90A0%E3%80%91nn.Conv1d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e34dca68",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-03T04:16:51.084920Z",
          "start_time": "2023-01-03T04:16:50.600718Z"
        },
        "id": "e34dca68"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06e4ab33",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-03T04:14:27.202240Z",
          "start_time": "2023-01-03T04:14:27.058461Z"
        },
        "id": "06e4ab33"
      },
      "source": [
        "# 卷积\n",
        "\n",
        "博客网址：http://t.csdn.cn/TGS1Y\n",
        "\n",
        "时延神经网络（[TDNNs](https://www.inf.ufrgs.br/~engel/data/media/file/cmp121/waibel89_TDNN.pdf)）常用于声纹识别领域，例如著名的X-VECTOR基础结构就是TDNNs；它可以视作一维卷积神经网络（1-d CNNs），甚至有人认为TDNNs是CNNs/LeNet-5的早期版本。\n",
        "\n",
        "计算机视觉盛行的如今，数字图像处理中**二维卷积**（空域滤波/模版运算/互相关运算）对于我们而言也不再陌生，无非就是中心数值等于按元素相乘后再相加嘛。\n",
        "\n",
        "可是，到底如何理解**一维卷积**？它和二维卷积又有什么联系？\n",
        "\n",
        "不妨通过实验，一探究竟。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93493de6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-03T04:14:27.202240Z",
          "start_time": "2023-01-03T04:14:27.058461Z"
        },
        "id": "93493de6"
      },
      "source": [
        "## 单输入/单输出通道\n",
        "\n",
        "首先，我们暂时忽略通道。假定输入为$[1, 2, -1, 1, -3]$，核函数为$[1, 0, -1]$**（卷积核是一维的，移动方向也自然是一维的）**，如果卷积核在输入向量上移动，请问结果是多少呢？可以看看我有没有算错。\n",
        "\n",
        "![](https://img-blog.csdnimg.cn/1da61a49f0344438b352ac7a0ba9a71c.png)\n",
        "\n",
        "顺带一提，这里输入是一行五列的矩阵。不过换一个角度，我们也可以认为每次输入的是3帧信息，并按照某种权重加和汇入1个新帧。\n",
        "\n",
        "这里的3是卷积核尺寸($kernel\\ size$)，从共享参数的全连接输入的角度说，3也是上下文所涵盖的范围,$(n-1,n+1) \\ or \\ \\{n-1, n, n+1\\}$。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7743ff6f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-03T04:16:51.093667Z",
          "start_time": "2023-01-03T04:16:51.085711Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7743ff6f",
        "outputId": "3a71ae6d-32ce-4811-cb83-717926d977be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[2., 1., 2.]]], grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 输入\n",
        "input = torch.tensor(\n",
        "    [\n",
        "        [\n",
        "            [1, 2, -1, 1, -3],\n",
        "        ]\n",
        "    ],\n",
        "    dtype=torch.float,\n",
        ")\n",
        "\n",
        "conv1d = nn.Conv1d(\n",
        "    in_channels=1,\n",
        "    out_channels=1,\n",
        "    kernel_size=3,\n",
        "    stride=1,\n",
        "    padding=0,\n",
        "    dilation=1,\n",
        "    bias=False,\n",
        "    padding_mode=\"zeros\",\n",
        ")\n",
        "\n",
        "\n",
        "# 卷积核\n",
        "conv1d.weight = nn.Parameter(\n",
        "    torch.tensor(\n",
        "        [\n",
        "            [\n",
        "                [1.0, 0, -1],\n",
        "            ]\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "# 输出\n",
        "conv1d(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d24c509",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-03T04:15:04.201498Z",
          "start_time": "2023-01-03T04:15:04.066037Z"
        },
        "id": "9d24c509"
      },
      "source": [
        "## 多输入/单输出通道\n",
        "\n",
        "但是，一般说来，TDNNs输入的声学特征并不是一个向量，而是一个矩阵，横轴（宽度）与时间有关【不固定】，纵轴（高度）和频率相关【**固定**】，所以它有时也被称为时频谱图（Spectrogram）。\n",
        "\n",
        "![](https://img-blog.csdnimg.cn/img_convert/f8a419a0a05853b4042c85ac7f1daf78.png)\n",
        "\n",
        "图片来自[MathWorks]( )。\n",
        "\n",
        "\n",
        "当然，上文所指的广义的时频谱也分很多种（常见的有MFCC、MFBank、MelSpec等），对应各种不同的处理方式（例如，模拟人耳对频率、声强的非线性，平稳信号等），不过它们一般都要经历短时傅里叶变换（分帧、加窗、离散傅里叶变换）。\n",
        "\n",
        "你还可以在 *[CHROME MUSIC LAB:SPECTROGRAM](https://musiclab.chromeexperiments.com/spectrogram/)*  上，亲自动手玩玩可视化自己的或自然的声音。\n",
        "\n",
        "![截图](https://img-blog.csdnimg.cn/12aa55c38418420ab5aca5c8a0a69a80.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e534bb9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-03T04:15:04.201498Z",
          "start_time": "2023-01-03T04:15:04.066037Z"
        },
        "id": "8e534bb9"
      },
      "source": [
        "我们暂时忽略输出通道。从一维卷积的视角说，[频率，时间] 应当被视作 [通道数，输入长度]，即每个通道各有一个卷积核或一组共享权重，每个通道独立计算再把各个通道的结果相加。\n",
        "\n",
        "假定输入为双通道（例如表示高频和低频）$$[[1, 2, -1, 1, -3],[3, 1, 0, -1, 2]]$$各通道上的核函数分别为$[1, 0, -1]$和$[0.5, 0, 0.5]$，请问这次结果又是多少呢？相信你肯定比我算的快。\n",
        "\n",
        "![](https://img-blog.csdnimg.cn/513fb240e9e84f86b6421758fc0d8efb.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d22cdc95",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-03T04:16:51.099295Z",
          "start_time": "2023-01-03T04:16:51.094973Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d22cdc95",
        "outputId": "66df1cf9-ebf1-4f3d-c55f-ea6190f23b82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[3.5000, 1.0000, 3.0000]]], grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 输入\n",
        "input = torch.tensor([[[1, 2, -1, 1, -3], [3, 1, 0, -1, 2]]], dtype=torch.float)\n",
        "\n",
        "conv1d = nn.Conv1d(\n",
        "    in_channels=2,\n",
        "    out_channels=1,\n",
        "    kernel_size=3,\n",
        "    stride=1,\n",
        "    padding=0,\n",
        "    dilation=1,\n",
        "    bias=False,\n",
        "    padding_mode=\"zeros\",\n",
        ")\n",
        "\n",
        "# 卷积核\n",
        "conv1d.weight = nn.Parameter(\n",
        "    torch.tensor(\n",
        "        [\n",
        "            [[1.0, 0, -1], [0.5, 0, 0.5]],\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "# 输出\n",
        "conv1d(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b44b6a70",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-03T04:15:20.227273Z",
          "start_time": "2023-01-03T04:15:20.224965Z"
        },
        "id": "b44b6a70"
      },
      "source": [
        "## 多输入/多输出通道\n",
        "\n",
        "最后，该如何理解输出通道呢？其实无非就是把单输出通道的那一份卷积核，扩增几倍而已。例如，仍然假定输入为双通道$$[[1, 2, -1, 1, -3],[3, 1, 0, -1, 2]]$$不过此时我们考虑简化的双**输出**通道的情况：\n",
        "\n",
        "第一份输出：各输入通道上的核函数分别为$[1, 0, -1]$和$[0.5, 0, 0.5]$；\n",
        "\n",
        "第二份输出：各输入通道上的核函数仍然是$[1, 0, -1]$和$[0.5, 0, 0.5]$。\n",
        "\n",
        "那么，我们就可以得到双倍的输出。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7d163f98",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-03T04:16:51.105328Z",
          "start_time": "2023-01-03T04:16:51.100857Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d163f98",
        "outputId": "846f7baa-8ccf-4d8d-f1cf-6cfe6156283c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[3.5000, 1.0000, 3.0000],\n",
              "         [3.5000, 1.0000, 3.0000]]], grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 输入\n",
        "input = torch.tensor([[[1, 2, -1, 1, -3], [3, 1, 0, -1, 2]]], dtype=torch.float)\n",
        "\n",
        "conv1d = nn.Conv1d(\n",
        "    in_channels=2,\n",
        "    out_channels=2,\n",
        "    kernel_size=3,\n",
        "    stride=1,\n",
        "    padding=0,\n",
        "    dilation=1,\n",
        "    bias=False,\n",
        "    padding_mode=\"zeros\",\n",
        ")\n",
        "\n",
        "# 卷积核\n",
        "conv1d.weight = nn.Parameter(\n",
        "    torch.tensor(\n",
        "        [\n",
        "            [[1.0, 0, -1], [0.5, 0, 0.5]],\n",
        "            [[1.0, 0, -1], [0.5, 0, 0.5]],\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "# 输出\n",
        "conv1d(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1705277f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-03T04:15:36.960098Z",
          "start_time": "2023-01-03T04:15:36.832051Z"
        },
        "id": "1705277f"
      },
      "source": [
        "## 一维卷积/二维卷积\n",
        "\n",
        "其实，如果将各个通道的一维卷积核拼接起来：所谓的一维卷积在各通道上的**加和**，完全可以用二维卷积核$[channels, kernel\\_ size]$按元素相乘后再**相加**理解。\n",
        "\n",
        "![](https://github.com/DURUII/HIMIA-course/blob/main/DURUII/res/conv1d_2d.svg?raw=1)\n",
        "\n",
        "所以，许多博主认为**一维卷积不代表卷积核是一维的，只代表卷积核的移动方向是一维的**；这种说法，从某种角度说，也有一定的道理。\n",
        "![请添加图片描述](https://img-blog.csdnimg.cn/3bbb29e5a71344e885000b98032fc7e0.png)\n",
        "\n",
        "\n",
        "不过值得注意的是，Pytorch中Conv1d和Conv2d输入维度不一样。\n",
        "\n",
        "例如，\n",
        "一维卷积 $[batch, channels, length]$，\n",
        "二维卷积 $[batch, channels, height, width]$。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "90b5fa46",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-03T04:16:51.111590Z",
          "start_time": "2023-01-03T04:16:51.106928Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90b5fa46",
        "outputId": "ab09917c-3491-4e43-f1d5-fa043bc7d032"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[3.5000, 1.0000, 3.0000]],\n",
              "\n",
              "         [[3.5000, 1.0000, 3.0000]]]], grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 输入\n",
        "input = torch.tensor([[[1, 2, -1, 1, -3], [3, 1, 0, -1, 2]]], dtype=torch.float)\n",
        "\n",
        "input = input.unsqueeze(dim=1)\n",
        "\n",
        "conv2d = nn.Conv2d(\n",
        "    in_channels=1,\n",
        "    out_channels=2,\n",
        "    kernel_size=(input.shape[2], 3),\n",
        "    stride=1,\n",
        "    padding=0,\n",
        "    dilation=1,\n",
        "    bias=False,\n",
        "    padding_mode=\"zeros\",\n",
        ")\n",
        "\n",
        "# 卷积核\n",
        "conv2d.weight = nn.Parameter(\n",
        "    torch.tensor(\n",
        "        [\n",
        "            [[[1.0, 0, -1], [0.5, 0, 0.5]]],\n",
        "            [[[1.0, 0, -1], [0.5, 0, 0.5]]],\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "# 输出\n",
        "conv2d(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "967db890",
      "metadata": {
        "id": "967db890"
      },
      "source": [
        "![](https://github.com/DURUII/HIMIA-course/blob/main/DURUII/res/v1_or_v2.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2d533f5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-05T01:38:37.872626Z",
          "start_time": "2023-01-05T01:38:37.868110Z"
        },
        "id": "f2d533f5"
      },
      "source": [
        "# 参考资料\n",
        "\n",
        "1. Daniel Povey et al. “Semi-Orthogonal Low-Rank Matrix Factorization for Deep Neural Networks..” conference of the international speech communication association(2018): n. pag.\n",
        "\n",
        "2. Zhang, A. , et al. \"Dive into Deep Learning.\" (2021).\n",
        "\n",
        "3. https://ww2.mathworks.cn/help/audio/ug/cocktail-party-source-separation-using-deep-learning-networks.html"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "vscode": {
      "interpreter": {
        "hash": "0f7732b7f14f8f1d9c463b6b041f7e8eb59326d10c6a2d43bfd07a7825d266f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
